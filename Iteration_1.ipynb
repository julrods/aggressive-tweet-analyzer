{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Iteration_1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julrods/cyber-bullying-detector/blob/main/Iteration_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWpayLDyjKBQ"
      },
      "source": [
        "REFERENCIA: https://swatimeena989.medium.com/bert-text-classification-using-keras-903671e0207d#011a\n",
        "\n",
        "- Javi: preguntar GCP\n",
        "- Probar binaria de nuevo, debería ir mejor\n",
        "- Este modelo es diferente al del ejemplo porque hay una Red densa metida en TFBErt for seq classification, no la ponemos manual. Por eso también le pasamos la máscara y el validation data de manera diferente al hacer fit\n",
        "\n",
        "\n",
        "Next steps:\n",
        "- 0. Conectar Jupyter a VM de GCP. \n",
        "- 0. Hacer predict con train para ver si hay overfitting\n",
        "- 1. Reentrenar con los mismo datos (aggression): Ver vector de losses (guardar) y añadir al nuevo vector cuando reentrene. \n",
        "- 2. Hacer epochs hasta que converja (llegue al mínimo). El modelo tiene un vector de losses y otro de accuracy. Buscar el mínimo de validation. \n",
        "- 3. Probar con todos los datos: usar los pesos que tengo y volverlo a entrenar con nuevos datos (cargar pesos antes de entrenar).\n",
        "- (4? Según cómo lo vea hacer resampling. )\n",
        "- 5. Productizarlo: Coger datos reales y clasificarlos. Buscar usuario de twitter con tweets ofensivos + usuario no ofensivo. Spider para scrappear IG. Dataset del https://projecte-equal.com/#dades\n",
        "\n",
        "Dudas: \n",
        "- Mirar el tema de la transformación al castellano\n",
        "- Pasa algo por haber cogido el código de la chica?\n",
        "\n",
        "VMs: \n",
        "- https://towardsdatascience.com/running-jupyter-notebook-in-google-cloud-platform-in-15-min-61e16da34d52\n",
        "- https://medium.com/swlh/how-to-use-google-cloud-and-gpu-build-simple-deep-learning-environment-c6eadff2a569"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vRX1i6WPD7Z"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yymChyEhPccH"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-4PXEPEPnkn",
        "outputId": "a25464f5-cf07-410b-e9f6-7706048e9d98"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.0)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSCmn831Pesa",
        "outputId": "e9344699-f4ef-4091-cc8a-9ec32eb35df0"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import re\n",
        "import unicodedata\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import keras\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "from keras.models import Model\n",
        "import keras.backend as K\n",
        "from sklearn.metrics import confusion_matrix,f1_score,classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import itertools\n",
        "from keras.models import load_model\n",
        "from sklearn.utils import shuffle\n",
        "#from transformers import *\n",
        "from transformers import BertTokenizer, TFBertModel, BertConfig, TFBertForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZvvUxu0b-mD",
        "outputId": "998ce393-e25a-4d87-f74c-9c7cf9dc2cb7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2I7D0SMPi6l"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-_SqNYqQF4-"
      },
      "source": [
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def clean_stopwords_shortwords(w):\n",
        "    stopwords_list=stopwords.words('english')\n",
        "    words = w.split() \n",
        "    clean_words = [word for word in words if (word not in stopwords_list) and len(word) > 2]\n",
        "    return \" \".join(clean_words) \n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "    w=clean_stopwords_shortwords(w)\n",
        "    w=re.sub(r'@\\w+', '',w)\n",
        "    return w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gLxlGbUQNAY"
      },
      "source": [
        "## Importing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVl0rtTPQaHr"
      },
      "source": [
        "# Import PyDrive and associated libraries.\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQwJ8UBgQmFb"
      },
      "source": [
        "# Download a file based on its file ID.\n",
        "file_id = '1W2uM-pWHd9TX0G9WjXKkAORDyqVoDbyu' # id of aggression_parsed_dataset\n",
        "downloaded = drive.CreateFile({'id': file_id})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piZT71uUQol_"
      },
      "source": [
        "### Import data from csv\n",
        "downloaded.GetContentFile('aggression_parsed_dataset.csv')  \n",
        "data_original = pd.read_csv('aggression_parsed_dataset.csv')\n",
        "data = data_original.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8afFFr7sQz_r",
        "outputId": "973198f3-d17f-4f62-afa8-d98348debed1"
      },
      "source": [
        "print('File has {} rows and {} columns'.format(data.shape[0],data.shape[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File has 115864 rows and 5 columns\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Mxrhg5_PRCNa",
        "outputId": "dedeb313-5449-4d9d-f31d-4874b6ee41a3"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Text</th>\n",
              "      <th>ed_label_0</th>\n",
              "      <th>ed_label_1</th>\n",
              "      <th>oh_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>`- This is not ``creative``.  Those are the di...</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>`  :: the term ``standard model`` is itself le...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>True or false, the situation as of March 200...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Next, maybe you could work on being less cond...</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>This page will need disambiguation.</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ... oh_label\n",
              "0      0  ...        0\n",
              "1      1  ...        0\n",
              "2      2  ...        0\n",
              "3      3  ...        0\n",
              "4      4  ...        0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xp-gogpSQ-32",
        "outputId": "e7fca468-6196-4985-bdf3-52e784913782"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 115864 entries, 0 to 115863\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count   Dtype  \n",
            "---  ------      --------------   -----  \n",
            " 0   index       115864 non-null  int64  \n",
            " 1   Text        115864 non-null  object \n",
            " 2   ed_label_0  115864 non-null  float64\n",
            " 3   ed_label_1  115864 non-null  float64\n",
            " 4   oh_label    115864 non-null  int64  \n",
            "dtypes: float64(2), int64(2), object(1)\n",
            "memory usage: 4.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OYgcyoNRIcE"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L4cVlx2Ra8w"
      },
      "source": [
        "# Select required columns\n",
        "data = data[['Text', 'oh_label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoOEvbbxRlTj"
      },
      "source": [
        "data = data.rename(columns = {'oh_label': 'label', 'Text': 'text'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVVbSzH0R1Zv",
        "outputId": "02594f87-2bea-4d0f-f4c9-432c6e579ca5"
      },
      "source": [
        "# Shuffle the dataset\n",
        "data = shuffle(data)\n",
        "\n",
        "# Print all the unique labels in the dataset   \n",
        "print('Available labels: ',data.label.unique())\n",
        "\n",
        "# Clean the text column using preprocess_sentence function defined above\n",
        "data['text']=data['text'].map(preprocess_sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Available labels:  [0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "OFSHXsjBSPuc",
        "outputId": "222b5fa7-a2a0-4017-9997-e184f92eeda7"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>51004</th>\n",
              "      <td>perhaps point involved georgian military whate...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69153</th>\n",
              "      <td>responding review continue pointed deletion pr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29324</th>\n",
              "      <td>funny thought input counted wikipedia regardle...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111665</th>\n",
              "      <td>hello hanibal please consider using line break...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43100</th>\n",
              "      <td>chicago bulls time roster</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text  label\n",
              "51004   perhaps point involved georgian military whate...      0\n",
              "69153   responding review continue pointed deletion pr...      0\n",
              "29324   funny thought input counted wikipedia regardle...      0\n",
              "111665  hello hanibal please consider using line break...      0\n",
              "43100                           chicago bulls time roster      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5BLyHxrSpaW"
      },
      "source": [
        "# Setting up BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkyxCh7ATKi7",
        "outputId": "a0a80326-9c67-439e-c70e-e85856234a55"
      },
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "bert_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
        "                                                             num_labels=len(data.label.unique()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6JJKkFZVYAp"
      },
      "source": [
        "## Example with a sentence to see how the tokenizer works"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ri3DHD5SWAaN",
        "outputId": "df159de1-82f9-4ad4-9d40-5ed9545cd4d9"
      },
      "source": [
        "sent = 'how to train the model, lets look at how a trained model calculates its prediction.'\n",
        "tokens = bert_tokenizer.tokenize(sent)\n",
        "print(tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['how', 'to', 'train', 'the', 'model', ',', 'lets', 'look', 'at', 'how', 'a', 'trained', 'model', 'calculate', '##s', 'its', 'prediction', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEtnG306WDJU"
      },
      "source": [
        "tokenized_sequence = bert_tokenizer.encode_plus(sent,\n",
        "                                               add_special_tokens = True,\n",
        "                                               max_length = 100,\n",
        "                                               truncation = True,\n",
        "                                               padding = 'max_length',\n",
        "                                               return_attention_mask = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHeVTgOOWMfJ",
        "outputId": "30f02b09-9ea0-4829-bb8c-cc1d65c4617c"
      },
      "source": [
        "tokenized_sequence.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQOEPLVEWxmc",
        "outputId": "802d3bb6-fd4f-492d-eecb-086bc1804d5c"
      },
      "source": [
        "# the zeros at the end are the padding to adjust to max length so that all the vectors have the same dimensions\n",
        "print(tokenized_sequence['input_ids'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 2129, 2000, 3345, 1996, 2944, 1010, 11082, 2298, 2012, 2129, 1037, 4738, 2944, 18422, 2015, 2049, 17547, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OZ0AAcGXBrc",
        "outputId": "6edb606e-f544-40ee-c38a-a36cc57bf594"
      },
      "source": [
        "# what is this??\n",
        "print(tokenized_sequence['token_type_ids'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F74QxBCuXDA2",
        "outputId": "23c60046-1086-4014-d10e-d2ef60c24857"
      },
      "source": [
        "# The attention mask signals if the model should pay attention to a token or not. It has one for the real tokens \n",
        "# and 0 for the padding tokens\n",
        "print(tokenized_sequence['attention_mask'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "NrgfnEG7W8Gr",
        "outputId": "78fc7fef-9c57-4a10-faee-01ce1305a87c"
      },
      "source": [
        "# Decoding. Special tokens like [CLS], [SEP] and [PAD] are added by the tokenizer\n",
        "bert_tokenizer.decode(tokenized_sequence['input_ids'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] how to train the model, lets look at how a trained model calculates its prediction. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jl9dnsQLZGLn"
      },
      "source": [
        "# Fine-tuning the pre-trained BERT model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_i_bkGLeDzx"
      },
      "source": [
        "## Encoding of the text data using BERT Tokenizer and obtaining the input_ids and attentions masks to feed into the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpf4UVVoZuC_",
        "outputId": "2fc32bcc-661b-4fcd-faf9-27ec03a4c2c5"
      },
      "source": [
        "sentences = data['text']\n",
        "labels = data['label']\n",
        "len(sentences), len(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(115864, 115864)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT7dXDvSZ_Mn"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "    bert_inp = bert_tokenizer.encode_plus(sent,\n",
        "                                          add_special_tokens = True,\n",
        "                                          max_length = 100,\n",
        "                                          truncation = True,\n",
        "                                          padding = 'max_length',\n",
        "                                          return_attention_mask = True)\n",
        "    input_ids.append(bert_inp['input_ids'])\n",
        "    attention_masks.append(bert_inp['attention_mask'])\n",
        "\n",
        "input_ids = np.asarray(input_ids)\n",
        "attention_masks = np.array(attention_masks)\n",
        "labels = np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AotFFlyeab0F"
      },
      "source": [
        "len(input_ids), len(attention_masks), len(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cJI3DXneJug"
      },
      "source": [
        "## Saving and loading the data into the pickle files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lso6dyaCbKIh"
      },
      "source": [
        "# print('Preparing the pickle file.....')\n",
        "# \n",
        "pickle_inp_path='/content/gdrive/MyDrive/Cyber-bullying-project/data/bert_inp.pkl'\n",
        "pickle_mask_path='/content/gdrive/MyDrive/Cyber-bullying-project/data/bert_mask.pkl'\n",
        "pickle_label_path='/content/gdrive/MyDrive/Cyber-bullying-project/data/bert_label.pkl'\n",
        "# \n",
        "# pickle.dump((input_ids), open(pickle_inp_path,'wb'))\n",
        "# pickle.dump((attention_masks), open(pickle_mask_path,'wb'))\n",
        "# pickle.dump((labels), open(pickle_label_path,'wb'))\n",
        "# \n",
        "# print('Pickle files saved as ', pickle_inp_path, pickle_mask_path, pickle_label_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KS14t2kvbyAc",
        "outputId": "2df6350f-40dd-4de7-f3af-8509decfb034"
      },
      "source": [
        "print('Loading the saved pickle files..')\n",
        "\n",
        "input_ids = pickle.load(open(pickle_inp_path, 'rb'))\n",
        "attention_masks = pickle.load(open(pickle_mask_path, 'rb'))\n",
        "labels = pickle.load(open(pickle_label_path, 'rb'))\n",
        "\n",
        "print('Input shape {} \\nAttention mask shape {} \\nInput label shape {}'.format(input_ids.shape, attention_masks.shape, labels.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading the saved pickle files..\n",
            "Input shape (115864, 100) \n",
            "Attention mask shape (115864, 100) \n",
            "Input label shape (115864,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHfPfdmLeQkZ"
      },
      "source": [
        "## Spitting into train, test and validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoIlhaedce1a",
        "outputId": "2ec2c898-0d94-4bc6-d66b-3072ecf704dd"
      },
      "source": [
        "train_inp, test_inp, train_label, test_label, train_mask, test_mask = train_test_split(input_ids,\n",
        "                                                                                    labels,\n",
        "                                                                                    attention_masks,\n",
        "                                                                                    test_size=0.2, \n",
        "                                                                                    stratify = labels)\n",
        "\n",
        "print('Train inp shape {} Test input shape {}\\nTrain label shape {} Test label shape {}\\nTrain attention mask shape {} Test attention mask shape {}'.format(train_inp.shape, test_inp.shape, train_label.shape, test_label.shape, train_mask.shape, test_mask.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train inp shape (92691, 100) Test input shape (23173, 100)\n",
            "Train label shape (92691,) Test label shape (23173,)\n",
            "Train attention mask shape (92691, 100) Test attention mask shape (23173, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFmK1Ocic3Gs",
        "outputId": "dd14439a-5065-4bd0-9da1-f328ed84bf2d"
      },
      "source": [
        "train_inp, val_inp, train_label, val_label, train_mask, val_mask = train_test_split(train_inp,\n",
        "                                                                                    train_label,\n",
        "                                                                                    train_mask,\n",
        "                                                                                    test_size=0.2,\n",
        "                                                                                    stratify = train_label)\n",
        "\n",
        "print('Train inp shape {} Val input shape {}\\nTrain label shape {} Val label shape {}\\nTrain attention mask shape {} Val attention mask shape {}'.format(train_inp.shape, val_inp.shape, train_label.shape, val_label.shape, train_mask.shape, val_mask.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train inp shape (74152, 100) Val input shape (18539, 100)\n",
            "Train label shape (74152,) Val label shape (18539,)\n",
            "Train attention mask shape (74152, 100) Val attention mask shape (18539, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9QBjf6ZdmtU"
      },
      "source": [
        "## Setting up the loss, metric and the optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAz5WZbpe8at"
      },
      "source": [
        "Read about callbacks: https://keras.io/api/callbacks/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PDC3z67eVbb",
        "outputId": "d8c1b4d0-8bb5-468a-e6d0-fcd74fb4f090"
      },
      "source": [
        "log_dir = 'tensorboard_data/tb_bert'\n",
        "model_save_path = '/content/gdrive/MyDrive/Cyber-bullying-project/models/bert_model.h5'\n",
        "\n",
        "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath = model_save_path,\n",
        "                                                save_weights_only = True,\n",
        "                                                monitor = 'val_loss',\n",
        "                                                mode = 'min',\n",
        "                                                save_best_only=True),\n",
        "             keras.callbacks.TensorBoard(log_dir = log_dir)]\n",
        "\n",
        "print('\\nBert Model', bert_model.summary())\n",
        "\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5,\n",
        "                                     epsilon=1e-08)\n",
        "\n",
        "bert_model.compile(loss = loss, optimizer = optimizer, metrics = [metric])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_for_sequence_classification\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (TFBertMainLayer)       multiple                  109482240 \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  1538      \n",
            "=================================================================\n",
            "Total params: 109,483,778\n",
            "Trainable params: 109,483,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Bert Model None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdiNjr7kmj8Q"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbXhgTn4fLni",
        "outputId": "452405e4-258d-4487-efa2-acde04ad89dc"
      },
      "source": [
        "history = bert_model.fit(x = [train_inp, train_mask],\n",
        "                         y = train_label,\n",
        "                         batch_size = 32,\n",
        "                         epochs = 2,\n",
        "                         validation_data = ([val_inp, val_mask], val_label), \n",
        "                         #callbacks = callbacks\n",
        "                         )\n",
        "\n",
        "#Modelo de Alberto:\n",
        "#history = model.fit(\n",
        "#    x={'input_ids': x['input_ids']},\n",
        "#    y={'oh_label': y[:,0]},\n",
        "#    validation_split=0.2,\n",
        "#    batch_size=64,\n",
        "#    epochs=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f7d97ce7d70>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f7d97ce7d70>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f7db2e96170> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7f7db2e96170> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "2318/2318 [==============================] - ETA: 0s - loss: 0.1692 - accuracy: 0.9362WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "2318/2318 [==============================] - 1581s 660ms/step - loss: 0.1692 - accuracy: 0.9362 - val_loss: 0.1458 - val_accuracy: 0.9419\n",
            "Epoch 2/2\n",
            "2318/2318 [==============================] - 1534s 662ms/step - loss: 0.1208 - accuracy: 0.9531 - val_loss: 0.1522 - val_accuracy: 0.9429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOxtNZX9v8tF"
      },
      "source": [
        "# Evaluating the performance of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMcyRUOsuPZ-"
      },
      "source": [
        "#%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FcRIBlsuTeL"
      },
      "source": [
        "#log_dir='tensorboard_data/bert_model'\n",
        "#%tensorboard --logdir {log_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYNM4LDDu57x"
      },
      "source": [
        "bert_model.save_weights(model_save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UhoCQfcujsE",
        "outputId": "f1671ac0-fc0c-45e1-9d4c-86c151bb30d7"
      },
      "source": [
        "trained_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "trained_model.compile(loss = loss,\n",
        "                      optimizer = optimizer, \n",
        "                      metrics = [metric])\n",
        "trained_model.load_weights(model_save_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRU33OEdvUTI",
        "outputId": "f1f8eaa1-b911-49a3-b468-60fbfede1d16"
      },
      "source": [
        "preds = trained_model.predict([test_inp, test_mask],\n",
        "                              batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH8Ycl8rvatZ"
      },
      "source": [
        "pred_labels = [np.argmax(pred) for pred in preds[0]]\n",
        "f1 = f1_score(test_label, pred_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XN6IOhhvoOi",
        "outputId": "dd93612c-aff7-41cb-aab6-32fa855e430c"
      },
      "source": [
        "print('F1 score', f1)\n",
        "print('Classification Report')\n",
        "print(classification_report(test_label, pred_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score 0.7807658058771149\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97     20217\n",
            "           1       0.82      0.74      0.78      2956\n",
            "\n",
            "    accuracy                           0.95     23173\n",
            "   macro avg       0.89      0.86      0.88     23173\n",
            "weighted avg       0.95      0.95      0.95     23173\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}