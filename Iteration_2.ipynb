{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Iteration_2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN/u4/7XuxZl+heqyNRJ6uz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julrods/cyber-bullying-detector/blob/main/Iteration_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWpayLDyjKBQ"
      },
      "source": [
        "**Changes from iteration 1:** changed the loss function from SparseCategoricalCrossentropy to BinaryCrossentropy and the SparseCategoricalAccuracy to BinaryAccuracy\n",
        "\n",
        "REFERENCIA: https://swatimeena989.medium.com/bert-text-classification-using-keras-903671e0207d#011a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vRX1i6WPD7Z"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yymChyEhPccH"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-4PXEPEPnkn",
        "outputId": "55e704ec-cb4e-488f-b138-096cc621d8fe"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSCmn831Pesa",
        "outputId": "3146102e-8c99-4d71-9695-6e70b66d1676"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import re\n",
        "import unicodedata\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import keras\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "from keras.models import Model\n",
        "import keras.backend as K\n",
        "from sklearn.metrics import confusion_matrix,f1_score,classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import itertools\n",
        "from keras.models import load_model\n",
        "from sklearn.utils import shuffle\n",
        "#from transformers import *\n",
        "from transformers import BertTokenizer, TFBertModel, BertConfig, TFBertForSequenceClassification"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZvvUxu0b-mD",
        "outputId": "5142832f-60e8-46fd-d414-cd3a4532b646"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2I7D0SMPi6l"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-_SqNYqQF4-"
      },
      "source": [
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def clean_stopwords_shortwords(w):\n",
        "    stopwords_list=stopwords.words('english')\n",
        "    words = w.split() \n",
        "    clean_words = [word for word in words if (word not in stopwords_list) and len(word) > 2]\n",
        "    return \" \".join(clean_words) \n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "    w=clean_stopwords_shortwords(w)\n",
        "    w=re.sub(r'@\\w+', '',w)\n",
        "    return w"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gLxlGbUQNAY"
      },
      "source": [
        "## Importing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVl0rtTPQaHr"
      },
      "source": [
        "# Import PyDrive and associated libraries.\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQwJ8UBgQmFb"
      },
      "source": [
        "# Download a file based on its file ID.\n",
        "file_id = '1W2uM-pWHd9TX0G9WjXKkAORDyqVoDbyu' # id of aggression_parsed_dataset\n",
        "downloaded = drive.CreateFile({'id': file_id})"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piZT71uUQol_"
      },
      "source": [
        "### Import data from csv\n",
        "downloaded.GetContentFile('aggression_parsed_dataset.csv')  \n",
        "data_original = pd.read_csv('aggression_parsed_dataset.csv')\n",
        "data = data_original.copy()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8afFFr7sQz_r",
        "outputId": "7adf97e2-d17c-4690-f626-d230238d3c93"
      },
      "source": [
        "print('File has {} rows and {} columns'.format(data.shape[0],data.shape[1]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File has 115864 rows and 5 columns\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Mxrhg5_PRCNa",
        "outputId": "62ca46ac-5cb6-4c0d-8460-6da157cee745"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Text</th>\n",
              "      <th>ed_label_0</th>\n",
              "      <th>ed_label_1</th>\n",
              "      <th>oh_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>`- This is not ``creative``.  Those are the di...</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>`  :: the term ``standard model`` is itself le...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>True or false, the situation as of March 200...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Next, maybe you could work on being less cond...</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>This page will need disambiguation.</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ... oh_label\n",
              "0      0  ...        0\n",
              "1      1  ...        0\n",
              "2      2  ...        0\n",
              "3      3  ...        0\n",
              "4      4  ...        0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xp-gogpSQ-32",
        "outputId": "3d8a9a12-fcd2-40f0-d0f3-4780940feec2"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 115864 entries, 0 to 115863\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count   Dtype  \n",
            "---  ------      --------------   -----  \n",
            " 0   index       115864 non-null  int64  \n",
            " 1   Text        115864 non-null  object \n",
            " 2   ed_label_0  115864 non-null  float64\n",
            " 3   ed_label_1  115864 non-null  float64\n",
            " 4   oh_label    115864 non-null  int64  \n",
            "dtypes: float64(2), int64(2), object(1)\n",
            "memory usage: 4.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OYgcyoNRIcE"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L4cVlx2Ra8w"
      },
      "source": [
        "# Select required columns\n",
        "data = data[['Text', 'oh_label']]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoOEvbbxRlTj"
      },
      "source": [
        "data = data.rename(columns = {'oh_label': 'label', 'Text': 'text'})"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVVbSzH0R1Zv",
        "outputId": "ed55d6bf-0104-44ac-f72f-0a58eda46e67"
      },
      "source": [
        "# Shuffle the dataset\n",
        "data = shuffle(data)\n",
        "\n",
        "# Print all the unique labels in the dataset   \n",
        "print('Available labels: ',data.label.unique())\n",
        "\n",
        "# Clean the text column using preprocess_sentence function defined above\n",
        "data['text']=data['text'].map(preprocess_sentence)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Available labels:  [0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "OFSHXsjBSPuc",
        "outputId": "b2842b8e-6a31-45a8-e3aa-660341358106"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5652</th>\n",
              "      <td>including including art credits part wiki proc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67505</th>\n",
              "      <td>addresses constantly change several unrelated ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72491</th>\n",
              "      <td>really think triollling mean wrong admit move ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76784</th>\n",
              "      <td>may acceptable article infobox supposed show m...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97228</th>\n",
              "      <td>yoyoyoyoyo wassup heyyyyyaaaaaaaaaa mean pleas...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  label\n",
              "5652   including including art credits part wiki proc...      0\n",
              "67505  addresses constantly change several unrelated ...      1\n",
              "72491  really think triollling mean wrong admit move ...      0\n",
              "76784  may acceptable article infobox supposed show m...      0\n",
              "97228  yoyoyoyoyo wassup heyyyyyaaaaaaaaaa mean pleas...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5BLyHxrSpaW"
      },
      "source": [
        "# Setting up BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkyxCh7ATKi7",
        "outputId": "2799b6aa-feb8-4bcc-e2fe-17fadc6b7838"
      },
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "bert_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
        "                                                             num_labels=len(data.label.unique()))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6JJKkFZVYAp"
      },
      "source": [
        "## Example with a sentence to see how the tokenizer works"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ri3DHD5SWAaN",
        "outputId": "df159de1-82f9-4ad4-9d40-5ed9545cd4d9"
      },
      "source": [
        "sent = 'how to train the model, lets look at how a trained model calculates its prediction.'\n",
        "tokens = bert_tokenizer.tokenize(sent)\n",
        "print(tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['how', 'to', 'train', 'the', 'model', ',', 'lets', 'look', 'at', 'how', 'a', 'trained', 'model', 'calculate', '##s', 'its', 'prediction', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEtnG306WDJU"
      },
      "source": [
        "tokenized_sequence = bert_tokenizer.encode_plus(sent,\n",
        "                                               add_special_tokens = True,\n",
        "                                               max_length = 100,\n",
        "                                               truncation = True,\n",
        "                                               padding = 'max_length',\n",
        "                                               return_attention_mask = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHeVTgOOWMfJ",
        "outputId": "30f02b09-9ea0-4829-bb8c-cc1d65c4617c"
      },
      "source": [
        "tokenized_sequence.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQOEPLVEWxmc",
        "outputId": "802d3bb6-fd4f-492d-eecb-086bc1804d5c"
      },
      "source": [
        "# the zeros at the end are the padding to adjust to max length so that all the vectors have the same dimensions\n",
        "print(tokenized_sequence['input_ids'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 2129, 2000, 3345, 1996, 2944, 1010, 11082, 2298, 2012, 2129, 1037, 4738, 2944, 18422, 2015, 2049, 17547, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OZ0AAcGXBrc",
        "outputId": "6edb606e-f544-40ee-c38a-a36cc57bf594"
      },
      "source": [
        "# what is this??\n",
        "print(tokenized_sequence['token_type_ids'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F74QxBCuXDA2",
        "outputId": "23c60046-1086-4014-d10e-d2ef60c24857"
      },
      "source": [
        "# The attention mask signals if the model should pay attention to a token or not. It has one for the real tokens \n",
        "# and 0 for the padding tokens\n",
        "print(tokenized_sequence['attention_mask'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "NrgfnEG7W8Gr",
        "outputId": "78fc7fef-9c57-4a10-faee-01ce1305a87c"
      },
      "source": [
        "# Decoding. Special tokens like [CLS], [SEP] and [PAD] are added by the tokenizer\n",
        "bert_tokenizer.decode(tokenized_sequence['input_ids'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] how to train the model, lets look at how a trained model calculates its prediction. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jl9dnsQLZGLn"
      },
      "source": [
        "# Fine-tuning the pre-trained BERT model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_i_bkGLeDzx"
      },
      "source": [
        "## Encoding of the text data using BERT Tokenizer and obtaining the input_ids and attentions masks to feed into the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpf4UVVoZuC_",
        "outputId": "2fc32bcc-661b-4fcd-faf9-27ec03a4c2c5"
      },
      "source": [
        "sentences = data['text']\n",
        "labels = data['label']\n",
        "len(sentences), len(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(115864, 115864)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT7dXDvSZ_Mn"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "    bert_inp = bert_tokenizer.encode_plus(sent,\n",
        "                                          add_special_tokens = True,\n",
        "                                          max_length = 100,\n",
        "                                          truncation = True,\n",
        "                                          padding = 'max_length',\n",
        "                                          return_attention_mask = True)\n",
        "    input_ids.append(bert_inp['input_ids'])\n",
        "    attention_masks.append(bert_inp['attention_mask'])\n",
        "\n",
        "input_ids = np.asarray(input_ids)\n",
        "attention_masks = np.array(attention_masks)\n",
        "labels = np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AotFFlyeab0F"
      },
      "source": [
        "len(input_ids), len(attention_masks), len(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cJI3DXneJug"
      },
      "source": [
        "## Saving and loading the data into the pickle files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lso6dyaCbKIh"
      },
      "source": [
        "# print('Preparing the pickle file.....')\n",
        "# \n",
        "pickle_inp_path='/content/gdrive/MyDrive/Cyber-bullying-project/data/bert_inp.pkl'\n",
        "pickle_mask_path='/content/gdrive/MyDrive/Cyber-bullying-project/data/bert_mask.pkl'\n",
        "pickle_label_path='/content/gdrive/MyDrive/Cyber-bullying-project/data/bert_label.pkl'\n",
        "# \n",
        "# pickle.dump((input_ids), open(pickle_inp_path,'wb'))\n",
        "# pickle.dump((attention_masks), open(pickle_mask_path,'wb'))\n",
        "# pickle.dump((labels), open(pickle_label_path,'wb'))\n",
        "# \n",
        "# print('Pickle files saved as ', pickle_inp_path, pickle_mask_path, pickle_label_path)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KS14t2kvbyAc",
        "outputId": "2bd90436-2594-4e41-b827-91242e1ecd3c"
      },
      "source": [
        "print('Loading the saved pickle files..')\n",
        "\n",
        "input_ids = pickle.load(open(pickle_inp_path, 'rb'))\n",
        "attention_masks = pickle.load(open(pickle_mask_path, 'rb'))\n",
        "labels = pickle.load(open(pickle_label_path, 'rb'))\n",
        "\n",
        "print('Input shape {} \\nAttention mask shape {} \\nInput label shape {}'.format(input_ids.shape, attention_masks.shape, labels.shape))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading the saved pickle files..\n",
            "Input shape (115864, 100) \n",
            "Attention mask shape (115864, 100) \n",
            "Input label shape (115864,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHfPfdmLeQkZ"
      },
      "source": [
        "## Spitting into train, test and validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoIlhaedce1a",
        "outputId": "0e5aedc1-de47-4aee-818f-fbc23c6210e6"
      },
      "source": [
        "train_inp, test_inp, train_label, test_label, train_mask, test_mask = train_test_split(input_ids,\n",
        "                                                                                    labels,\n",
        "                                                                                    attention_masks,\n",
        "                                                                                    test_size=0.2, \n",
        "                                                                                    stratify = labels)\n",
        "\n",
        "print('Train inp shape {} Test input shape {}\\nTrain label shape {} Test label shape {}\\nTrain attention mask shape {} Test attention mask shape {}'.format(train_inp.shape, test_inp.shape, train_label.shape, test_label.shape, train_mask.shape, test_mask.shape))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train inp shape (92691, 100) Test input shape (23173, 100)\n",
            "Train label shape (92691,) Test label shape (23173,)\n",
            "Train attention mask shape (92691, 100) Test attention mask shape (23173, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFmK1Ocic3Gs",
        "outputId": "94629077-76dc-4d45-e8d2-4c19c31849d9"
      },
      "source": [
        "train_inp, val_inp, train_label, val_label, train_mask, val_mask = train_test_split(train_inp,\n",
        "                                                                                    train_label,\n",
        "                                                                                    train_mask,\n",
        "                                                                                    test_size=0.2,\n",
        "                                                                                    stratify = train_label)\n",
        "\n",
        "print('Train inp shape {} Val input shape {}\\nTrain label shape {} Val label shape {}\\nTrain attention mask shape {} Val attention mask shape {}'.format(train_inp.shape, val_inp.shape, train_label.shape, val_label.shape, train_mask.shape, val_mask.shape))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train inp shape (74152, 100) Val input shape (18539, 100)\n",
            "Train label shape (74152,) Val label shape (18539,)\n",
            "Train attention mask shape (74152, 100) Val attention mask shape (18539, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9QBjf6ZdmtU"
      },
      "source": [
        "## Setting up the loss, metric and the optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAz5WZbpe8at"
      },
      "source": [
        "Read about callbacks: https://keras.io/api/callbacks/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PDC3z67eVbb",
        "outputId": "707a3ac5-49bd-4bb8-f353-e86913f7ba09"
      },
      "source": [
        "log_dir = 'tensorboard_data/tb_bert'\n",
        "model_save_path = '/content/gdrive/MyDrive/Cyber-bullying-project/models/bert_model2.h5'\n",
        "\n",
        "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath = model_save_path,\n",
        "                                                save_weights_only = True,\n",
        "                                                monitor = 'val_loss',\n",
        "                                                mode = 'min',\n",
        "                                                save_best_only=True),\n",
        "             keras.callbacks.TensorBoard(log_dir = log_dir)]\n",
        "\n",
        "print('\\nBert Model', bert_model.summary())\n",
        "\n",
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "metric = tf.keras.metrics.BinaryAccuracy('accuracy')\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5,\n",
        "                                     epsilon=1e-08)\n",
        "\n",
        "bert_model.compile(loss = loss, optimizer = optimizer, metrics = [metric])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_for_sequence_classification\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (TFBertMainLayer)       multiple                  109482240 \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  1538      \n",
            "=================================================================\n",
            "Total params: 109,483,778\n",
            "Trainable params: 109,483,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Bert Model None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdiNjr7kmj8Q"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbXhgTn4fLni",
        "outputId": "faa1037d-33c2-47db-bce5-5e61181126bb"
      },
      "source": [
        "history = bert_model.fit(x = [train_inp, train_mask],\n",
        "                         y = train_label,\n",
        "                         batch_size = 32,\n",
        "                         epochs = 2,\n",
        "                         validation_data = ([val_inp, val_mask], val_label), \n",
        "                         callbacks = callbacks\n",
        "                         )\n",
        "\n",
        "#Modelo de Alberto:\n",
        "#history = model.fit(\n",
        "#    x={'input_ids': x['input_ids']},\n",
        "#    y={'oh_label': y[:,0]},\n",
        "#    validation_split=0.2,\n",
        "#    batch_size=64,\n",
        "#    epochs=2)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "2318/2318 [==============================] - ETA: 0s - loss: 0.2995 - accuracy: 0.9051WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "2318/2318 [==============================] - 1571s 670ms/step - loss: 0.2995 - accuracy: 0.9051 - val_loss: 0.2139 - val_accuracy: 0.9399\n",
            "Epoch 2/2\n",
            "2318/2318 [==============================] - 1545s 667ms/step - loss: 0.2182 - accuracy: 0.9319 - val_loss: 0.2493 - val_accuracy: 0.9399\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOxtNZX9v8tF"
      },
      "source": [
        "# Evaluating the performance of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMcyRUOsuPZ-"
      },
      "source": [
        "#%load_ext tensorboard"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FcRIBlsuTeL"
      },
      "source": [
        "#log_dir='tensorboard_data/bert_model'\n",
        "#%tensorboard --logdir {log_dir}"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYNM4LDDu57x"
      },
      "source": [
        "bert_model.save_weights(model_save_path)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UhoCQfcujsE",
        "outputId": "ce91da47-93a5-4aaf-deda-d2b7b546c67e"
      },
      "source": [
        "trained_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "trained_model.compile(loss = loss,\n",
        "                      optimizer = optimizer, \n",
        "                      metrics = [metric])\n",
        "trained_model.load_weights(model_save_path)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRU33OEdvUTI",
        "outputId": "363c5547-0b78-4631-e160-752edb69b4b5"
      },
      "source": [
        "preds = trained_model.predict([test_inp, test_mask],\n",
        "                              batch_size=32)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH8Ycl8rvatZ"
      },
      "source": [
        "pred_labels = [np.argmax(pred) for pred in preds[0]]\n",
        "f1 = f1_score(test_label, pred_labels)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XN6IOhhvoOi",
        "outputId": "3b3e1490-ba3a-415a-da78-ab3d9f66378c"
      },
      "source": [
        "print('F1 score', f1)\n",
        "print('Classification Report')\n",
        "print(classification_report(test_label, pred_labels))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score 0.7620931487142599\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97     20217\n",
            "           1       0.81      0.72      0.76      2956\n",
            "\n",
            "    accuracy                           0.94     23173\n",
            "   macro avg       0.89      0.85      0.86     23173\n",
            "weighted avg       0.94      0.94      0.94     23173\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlYul4o3GE0A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}